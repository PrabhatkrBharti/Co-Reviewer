{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "import os\n",
    "import fitz\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder = \"ICLR_2020_papers\"\n",
    "output_folder = \"ICLR_2020_LLM_reviews\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_generator = Agent(\n",
    "    role=\"Review Generator\",\n",
    "    goal=\"\"\"\n",
    "    Generate a structured, detailed review of a research paper in paragraph form (max 300 words)  covering all major sections (Abstract, Introduction, Methodology, Experiments, Results, etc.).\n",
    "    - Assess aspects such as originality, impact, clarity, empirical soundness, and recommendation in the paper.\n",
    "    - Clearly mention the paper's title and domain.\n",
    "    - Discuss strengths, weaknesses, and potential areas for improvement.\n",
    "    - The review should be thorough and critical, analyzing the paper as if you are a domain expert in the field.\n",
    "    - Avoid merely summarizing the paper; engage deeply with its strengths, limitations, and impact.\n",
    "    - Be constructively critical—highlight flaws, but in a professional and polite tone.\n",
    "    - Provide constructive criticism with actionable suggestions.\n",
    "    - Include a score for rating (out of 10) and acceptance decision (Strong Reject → Strong Accept) and confidence score (a value from 1 to 5),\n",
    "      which will be refined in later steps.\n",
    "    - The final decision should adhere to these thresholds:   1-3 → Strong Reject, 3-5 → Weak Reject, 5-7 → Weak Accept, 7-10 → Strong Accept.\n",
    "    - Review the paper as if you are the expert of that domain.\n",
    "    - Rating, Decision and confidence scored should not be part of the 300 words. They are to be written in a list form at the end of the review.\n",
    "    \"\"\",\n",
    "    backstory=\"You are an AI research reviewer trained to critically analyze scientific papers and provide structured, insightful critiques.\",\n",
    "    openai_model=\"gpt-4o\",\n",
    "    verbose=True,\n",
    "    memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_evaluator = Agent(\n",
    "    role=\"Review Evaluator\",\n",
    "    goal=\"\"\"\n",
    "    Evaluate the generated review for depth, specificity, and logical consistency.\n",
    "\n",
    "    Key Evaluation Criteria:\n",
    "    - Ensure that all major sections (Abstract, Introduction, Methodology, Experiments, etc.) are covered and all aspects (Originality, Impact, Clarity, etc.) are analyzed.\n",
    "    - Insightfulness: How does the paper contribute to existing work? Is it impactful?\n",
    "    - Coverage: Does the review discuss all key sections of the paper? What is missing?\n",
    "    - Constructive Criticism: Are actionable improvement suggestions given?\n",
    "    - Politeness & Code of Conduct: Is criticism expressed professionally and politely?\n",
    "    - Score Consistency: Does the rating and confidence score align with the review text?\n",
    "    - Hedge Words Detection: If there are excessive hedge words (\"might,\" \"could,\" \"potentially\"), reduce the confidence score.\n",
    "    - Check if the reviewer is consistent with the review, at sentence level and aspect level\n",
    "    Output:\n",
    "    - Identify missing aspects in the review.\n",
    "    - Suggest improvements to make the review more insightful and constructive.\n",
    "    - Flag any inconsistencies between review text and final rating.\n",
    "    \"\"\",\n",
    "    backstory=\"You are an AI expert in review quality assessment, ensuring fairness, depth, and logical alignment in critiques.\",\n",
    "    verbose=True,\n",
    "    memory=True,\n",
    "    openai_model=\"gpt-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_flagger = Agent(\n",
    "    role=\"Mismatch Flagging & Counterfactual Agent\",\n",
    "    goal=\"\"\"\n",
    "    Critically analyze the review for logical inconsistencies, contradictions, or missing critiques.\n",
    "    Incorporate evaluator and mismatch agent feedback to refine the review.\n",
    "    Key Checks:\n",
    "    - Highlight missing sections and aspects.\n",
    "    - Rating Alignment: Does the final score (out of 10) and acceptance decision reflect the review's actual content?\n",
    "    - Section Coverage: How many sections of the paper does the review cover? Which sections are missing?\n",
    "    - Aspect Coverage: How many aspects of the paper does the review cover? Which asepects are missing?\n",
    "    - Depth Analysis: Does the review discuss technical details, methodology, results, and limitations adequately?\n",
    "    - Counterfactual Reasoning: How would the review change if certain aspects were emphasized more or removed?\n",
    "      (Example: If the results section was stronger, would the review be more positive?)\n",
    "    - Tone Check: Ensure the review follows a constructive, polite, and professional tone.\n",
    "      - If criticism is too harsh, suggest ways to soften it while keeping the critique valid.\n",
    "\n",
    "    Output:\n",
    "    - Identify logical gaps or contradictions in the review.\n",
    "    - Suggest specific revisions to ensure fairn  ess, depth, and consistency.\n",
    "    \"\"\",\n",
    "    backstory=\"You are an AI specializing in logical consistency, depth analysis, and counterfactual reasoning for research critiques.\",\n",
    "    verbose=True,\n",
    "    memory=True,\n",
    "    openai_model=\"gpt-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refinement_agent = Agent(\n",
    "    role=\"Refinement Agent\",\n",
    "    goal=\"\"\"\n",
    "    Improve the review by integrating feedback from the Evaluator and Counterfactual Agent.\n",
    "\n",
    "    - Ensure that the rating (out of 10) and final decision (Strong Accept → Strong Reject) logically reflect the critique and align with the set thresholds.\n",
    "    - Expand on missing sections and make the review more insightful.\n",
    "    - Ensure the tone is professional, constructive, and polite.\n",
    "    - Add actionable improvement suggestions (what can the authors do to improve?).\n",
    "    - Ensure that the rating (out of 10) and final decision (Strong Accept → Strong Reject) logically reflect the critique.\n",
    "    Strict Decision Thresholds (NO EXCEPTIONS):\n",
    "    - Strong Reject: 1-3\n",
    "    - Weak Reject: 3-5\n",
    "    - Weak Accept: 5-6\n",
    "    - Strong Accept: 7-10\n",
    "    - Final review must contain point of action for the authors to improve the paper.\n",
    "    Final Review Format:\n",
    "    - Structured review (paragraph form, max 300 words)\n",
    "    - Rating (out of 10)\n",
    "    - Acceptance Decision STRICTLY FOLLOWING THE DECISION THRESHOLDS(Strong Accept, Weak Accept, Weak Reject, Strong Reject)\n",
    "    - Confidence Score (1-5)\n",
    "    \"\"\",\n",
    "    backstory=\"You refine research reviews, ensuring clarity, fairness, and logical coherence.\",\n",
    "    verbose=True,\n",
    "    memory=True,\n",
    "    openai_model=\"gpt-4o\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdf_file in os.listdir(pdf_folder):\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "        paper_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "        # Define tasks\n",
    "        generate_review_task = Task(\n",
    "            description=f\"\"\"\n",
    "            Generate an initial structured review of the provided research paper {paper_text} (include the paper title and domain) in no more than 300 words.\n",
    "            The review should highlight the paper's strengths, weaknesses, and potential areas for improvement.\n",
    "            Do not include generic statements. The output should also include a placeholder and also and intial value for a rating and acceptance decision and confidence score that will later be refined.\n",
    "            The paper should cover all the following aspects:\n",
    "                \"- Abstract (ABS)\\n\"\n",
    "                \"- Introduction (INT)\\n\"\n",
    "                \"- Related Works (RWK)\\n\"\n",
    "                \"- Problem Definition/Idea (PDI)\\n\"\n",
    "                \"- Data/Datasets (DAT)\\n\"\n",
    "                \"- Methodology (MET)\\n\"\n",
    "                \"- Experiments (EXP)\\n\"\n",
    "                \"- Results (RES)\\n\"\n",
    "                \"- Tables & Figures (TNF)\\n\"\n",
    "                \"- Analysis (ANA)\\n\"\n",
    "                \"- Future Work (FWK)\\n\"\n",
    "                \"- Overall (OAL)\\n\"\n",
    "                \"- Bibliography (BIB)\\n\"\n",
    "                \"- External Knowledge (EXT)\\n\"\n",
    "                \"\\n\"\n",
    "                \"Additionally, assess the paper based on the following aspects:\\n\"\n",
    "                \"- Appropriateness (APR)\\n\"\n",
    "                \"- Originality (NOV)\\n\"\n",
    "                \"- Significance (IMP)\\n\"\n",
    "                \"- Meaningful Comparison (CMP)\\n\"\n",
    "                \"- Presentation & Formatting (PNF)\\n\"\n",
    "                \"- Recommendation (REC)\\n\"\n",
    "                \"- Empirical & Theoretical Soundness (EMP)\\n\"\n",
    "                \"- Substance (SUB)\\n\"\n",
    "                \"- Clarity (CLA)\\n\"\n",
    "                \"\\n\"\n",
    "                \"Conclude with a final rating (1-10), confidence score (1-5), and recommendation (Strong Reject → Strong Accept), but not in the review text.\",\n",
    "            The paper should cover all the following sections\n",
    "            \"\"\",\n",
    "            agent=review_generator,\n",
    "            expected_output=\"A structured review highlighting strengths, weaknesses, and improvement areas.\"\n",
    "        )\n",
    "\n",
    "        evaluate_review_task = Task(\n",
    "            description=f\"\"\"\n",
    "            Assess the review of the paper: {paper_text} based on depth, politeness, hedge words, and rating consistency.\" \\n\n",
    "            Provide detailed feedback, especially noting if the rating and decision are logically aligned with the strengths and weaknesses discussed.\\n\n",
    "            Ensure all sections (ABS, INT, RWK, PDI, DAT, MET, EXP, RES, TNF, ANA, FWK, OAL, BIB, EXT) are covered.\\n\"\n",
    "            Ensure all Aspects (APR, NOV, IMP, CMP, PNF, REC, EMP, SUB, CLA) are assessed.\\n\"\n",
    "            \"\"\",\n",
    "            agent=review_evaluator,\n",
    "            context=[generate_review_task],\n",
    "            expected_output=\"An evaluation report highlighting missing aspects and tone issues.\"\n",
    "        )\n",
    "\n",
    "        flag_mismatches_task = Task(\n",
    "            description=f\"\"\"\n",
    "            Refine the review for the paper: {paper_text} by addressing all flagged issues, ensuring depth and consistency.\n",
    "              - Check whether the final rating and decision (e.g., '8/10, Strong Accept') match the review's content.\n",
    "              - Suggest specific counterfactual scenarios: How would the review change if certain aspects were emphasized differently?\n",
    "              - Provide **specific** recommendations for aligning the review critique with its final scoring.\n",
    "              - Check whether the critical sections and aspects are missing from the review or not.\n",
    "              \"\"\",\n",
    "            agent=mismatch_flagger,\n",
    "            context=[generate_review_task],\n",
    "            expected_output=\"A list of inconsistencies, counterfactual insights, and improvement suggestions.\"\n",
    "        )\n",
    "\n",
    "        generate_final_review_task = Task(\n",
    "            description=f\"\"\"\n",
    "            Refine the initial review of {paper_text} by incorporating feedback from the evaluator and counterfactual agent.\n",
    "            - Ensure that the review is in a paragraph form in not more than 300 words.\n",
    "            - Ensure that the review has depth and consistency.\n",
    "            - Ensure logical consistency and fair critique.\n",
    "            - Explicitly mention the paper's title and field/domain.\n",
    "            - Clearly mention strengths, weaknesses, and improvement suggestions.\n",
    "            - The final review must also include at end seperately listed down:\n",
    "              - A Rating (out of 10 for the paper) that logically reflects the critique.\n",
    "              - An Acceptance Decision(Strong Accept, Weak Accept, Weak Reject, Strong Reject).\n",
    "              - A confidence score (1-5) for the review.\n",
    "            -**Strict Decision Thresholds (NO EXCEPTIONS):**\n",
    "            - **Strong Reject:** 1-3\n",
    "            - **Weak Reject:** 3-5\n",
    "            - **Weak Accept:** 5-6\n",
    "            - **Strong Accept:** 7-10\n",
    "            - **Strictly follow these thresholds for the final decision**. If the paper is very good and flawless then only consider giving a score of 7 or more than 7.\n",
    "            -If the paper is given a weak accept, then the rating shouldnt be more than 6. and so on for all the thresholds.\n",
    "            - Strong accept to be given to a paper if it is very good and flawless.\n",
    "            **Ensure that critical reviews have lower ratings and rejections, and positive reviews have higher ratings and acceptances.**\n",
    "            -  Review the paper as if you are the expert of that domain.\n",
    "            \"\"\",\n",
    "            agent=refinement_agent,\n",
    "            context=[generate_review_task, evaluate_review_task, flag_mismatches_task],\n",
    "            expected_output=\"A final, polished review with clear action points. Review with structured output: Review text, Rating (out of 10), Decision, Confidence Score (1-10).\"\n",
    "        )\n",
    "\n",
    "        crew = Crew(\n",
    "            agents=[review_generator, review_evaluator, mismatch_flagger, refinement_agent],\n",
    "            tasks=[generate_review_task, evaluate_review_task, flag_mismatches_task, generate_final_review_task],\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        crew.kickoff()\n",
    "\n",
    "        final_review_output = generate_final_review_task.output.raw\n",
    "        \n",
    "        output_file = os.path.join(output_folder, f\"{os.path.splitext(pdf_file)[0]}_review.txt\")\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(final_review_output)\n",
    "\n",
    "        print(f\"Saved final review for {pdf_file} to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_output = generate_review_task.output\n",
    "print(f\"Raw Output: {task_output.raw}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_output = evaluate_review_task.output\n",
    "print(f\"Task 2: {task_output.raw}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_output = flag_mismatches_task.output\n",
    "print(f\"Task 3: {task_output.raw}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_output = generate_final_review_task.output\n",
    "print(f\"Final review: {task_output.raw}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
